{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5afb6f",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "<img src=\"Images/logistic_regression.png\" alt=\"isolated\" width=\"500\"/>\n",
    "\n",
    "We have a model ... and given that model, we try to minimize the lost between the real values y and our prediction y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594ebf4",
   "metadata": {},
   "source": [
    "### Sentiment Representation of Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43aaf0",
   "metadata": {},
   "source": [
    "We create a vocabulary and represent the words in _Sparse Represantition_.\n",
    "\n",
    "Given a tweet, or some text, you can represent it as a vector of dimension VV, where VV corresponds to your vocabulary size. If you had the tweet \"I am happy because I am learning NLP\", then you would put a 1 in the corresponding index for any word in the tweet, and a 0 otherwise.\n",
    "\n",
    "<img src=\"Images/sparse_repr.png\" alt=\"isolated\" width=\"500\"/>\n",
    "\n",
    "As you can see, as VV gets larger, the vector becomes more sparse. Furthermore, we end up having many more features and end up training \\thetaθ VV parameters. This could result in larger training time, and large prediction time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01a223",
   "metadata": {},
   "source": [
    "Instead of n dimensional vector representation for each tweet, we can use another method as below;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df4fc13",
   "metadata": {},
   "source": [
    "<img src=\"Images/freqs.png\" alt=\"isolated\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d6f9c",
   "metadata": {},
   "source": [
    "Previously, this vector was of dimension VV. Now, you will represent it with a vector of dimension 3. To do so, you have to create a dictionary to map the word, and the class it appeared in (positive or negative) to the number of times that word appeared in its corresponding class. \n",
    "\n",
    "<div>\n",
    "    <img src=\"Images/pos_freqs.png\" alt=\"isolated\" width=\"450\" align='left' />\n",
    "\n",
    "    <img src=\"Images/neg_freqs.png\" alt=\"isolated\" width=\"450\" align='right'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0b65a",
   "metadata": {},
   "source": [
    "Hence you end up getting the following feature vector $[1,8,11]$. 1 corresponds to the bias, 8 the positive feature, and 11 the negative feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dad2bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca637fee",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a81f8b",
   "metadata": {},
   "source": [
    "When preprocessing, you have to perform the following:\n",
    "\n",
    "1. Eliminate handles and URLs\n",
    "\n",
    "2. Tokenize the string into words. \n",
    "\n",
    "3. Remove stop words like \"and, is, a, on, etc.\"\n",
    "\n",
    "4. Stemming- or convert every word to its stem. Like dancer, dancing, danced, becomes 'danc'. You can use porter stemmer to take care of this. \n",
    "\n",
    "5. Convert all your words to lower case.\n",
    "\n",
    "For example the following tweet \"@YMourri and @AndrewYNg are tuning a GREAT AI model at https://deeplearning.ai!!!\" after preprocessing becomes $[tun,great,ai,model]$.\n",
    "\n",
    "Hence you can see how we eliminated handles, tokenized it into words, removed stop words, performed stemming, and converted everything to lower case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa11da",
   "metadata": {},
   "source": [
    "So our work comes together as follows;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566cd0c",
   "metadata": {},
   "source": [
    "<img src=\"Images/put_it_together.png\" alt=\"isolated\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561bbbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
